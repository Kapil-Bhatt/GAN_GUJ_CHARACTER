{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Guj_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMK1xBmSi9nzmsH9AT34isS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kapil-Bhatt/GAN_GUJ_CHARACTER/blob/master/Guj_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TufhP0vuiaP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4d35d2ee-00f2-4944-ddd5-4b67c7ea52f6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eoQvXd4Jq4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_wzqZvRJzQG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#image size is 112*112 pixels\n",
        "img_rows = 112\n",
        "img_cols = 112\n",
        "channels = 1\n",
        "img_shape = (img_rows, img_cols, channels)\n",
        "latent_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GWmiGwIVKUIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#generator function input latent dimention 100\n",
        "def build_generator():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(512 * 28 * 28, activation=\"relu\", input_dim=latent_dim))\n",
        "    model.add(Reshape((28, 28, 512)))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(UpSampling2D())\n",
        "    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Activation(\"relu\"))\n",
        "    model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n",
        "    model.add(Activation(\"tanh\"))\n",
        "    model.summary()\n",
        "    noise = Input(shape=(latent_dim,))\n",
        "    img = model(noise)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJoeQsWOKXuL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#descriminator function \n",
        "def build_discriminator():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(ZeroPadding2D(padding=((0, 1), (0, 1))))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.summary()\n",
        "    img = Input(shape=img_shape)\n",
        "    validity = model(img)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J70JtGARKhzY",
        "colab_type": "code",
        "outputId": "3c9bc056-0896-4132-f2af-90b1401b4e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        }
      },
      "source": [
        "#compile discriminator \n",
        "optimizer = Adam(0.0002, 0.5)\n",
        "discriminator = build_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['accuracy'])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_29 (Conv2D)           (None, 56, 56, 32)        320       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)   (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 56, 56, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 28, 28, 64)        18496     \n",
            "_________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPaddin (None, 29, 29, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_21 (Batc (None, 29, 29, 64)        256       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)   (None, 29, 29, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 29, 29, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 15, 15, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_22 (Batc (None, 15, 15, 128)       512       \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)   (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 15, 15, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 15, 15, 256)       295168    \n",
            "_________________________________________________________________\n",
            "batch_normalization_23 (Batc (None, 15, 15, 256)       1024      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)   (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 57601     \n",
            "=================================================================\n",
            "Total params: 447,233\n",
            "Trainable params: 446,337\n",
            "Non-trainable params: 896\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFcAUD_vKqXj",
        "colab_type": "code",
        "outputId": "60e0e11f-e9cf-4619-85e3-5fc362df530b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "generator = build_generator()\n",
        "z = Input(shape=(100,))\n",
        "img = generator(z)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_10 (Dense)             (None, 401408)            40542208  \n",
            "_________________________________________________________________\n",
            "reshape_5 (Reshape)          (None, 28, 28, 512)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_9 (UpSampling2 (None, 56, 56, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 56, 56, 128)       589952    \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 56, 56, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_10 (UpSampling (None, 112, 112, 128)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 112, 112, 64)      73792     \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 112, 112, 64)      256       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 112, 112, 1)       577       \n",
            "_________________________________________________________________\n",
            "activation_15 (Activation)   (None, 112, 112, 1)       0         \n",
            "=================================================================\n",
            "Total params: 41,207,297\n",
            "Trainable params: 41,206,913\n",
            "Non-trainable params: 384\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtdtfZnGK7Hm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#combined of discriminator and generator GAN model \n",
        "discriminator.trainable = False\n",
        "valid = discriminator(img)\n",
        "combined = Model(z, valid)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRsR1plYK-ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train the model\n",
        "def train(epochs, batch_size, save_interval):\n",
        "    #make directory\n",
        "    os.makedirs('images', exist_ok=True)\n",
        "\n",
        "    #read our csv file from drive\n",
        "    read=pd.read_csv(\"/content/drive/My Drive/Dataset/img_pixels_update.csv\").values\n",
        "    X_train=np.array\n",
        "    X_train= read.reshape(216,112,112)\n",
        "\n",
        "    # Rescale -1 to 1\n",
        "    X_train = X_train / 127.5 - 1.\n",
        "    X_train = np.expand_dims(X_train, axis=3)\n",
        "\n",
        "    # Adversarial gives label 1 to valid images and 0 to fake \n",
        "    valid = np.ones((batch_size, 1))\n",
        "    fake = np.zeros((batch_size, 1))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Select a random real images\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        real_imgs = X_train[idx]\n",
        "\n",
        "        # Sample noise and generate a batch of fake images\n",
        "        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n",
        "        fake_imgs = generator.predict(noise)\n",
        "\n",
        "        # Train the discriminator\n",
        "        D_loss_real = discriminator.train_on_batch(real_imgs, valid)\n",
        "        D_loss_fake = discriminator.train_on_batch(fake_imgs, fake)\n",
        "        D_loss = 0.5 * np.add(D_loss_real, D_loss_fake)\n",
        "\n",
        "        # Train the generator\n",
        "        g_loss = combined.train_on_batch(noise, valid)\n",
        "\n",
        "        # If at save interval\n",
        "        if epoch % save_interval == 0:\n",
        "            # Print the progress\n",
        "            print(\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, D_loss[0], 100 * D_loss[1], g_loss))\n",
        "            # Save generated image samples\n",
        "            save_imgs(epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evTXyFCqLHKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_imgs(epoch):\n",
        "    r, c = 4, 4\n",
        "    noise = np.random.normal(0, 1, (r * c, latent_dim))\n",
        "    gen_imgs = generator.predict(noise)\n",
        "\n",
        "    # Rescale images 0 - 1\n",
        "    gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "    fig, axs = plt.subplots(r, c)\n",
        "    cnt = 0\n",
        "    for i in range(r):\n",
        "        for j in range(c):\n",
        "            axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
        "            axs[i, j].axis('off')\n",
        "            cnt += 1\n",
        "    fig.savefig(\"images/characters_%d.png\" % epoch)\n",
        "    plt.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn70MiwfLSPn",
        "colab_type": "code",
        "outputId": "9cb17f61-182a-47ad-ad01-a63541e40507",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "train(epochs=2000, batch_size=2, save_interval=50)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0 [D loss: 0.160586, acc.: 100.00%] [G loss: 2.949872]\n",
            "50 [D loss: 0.630973, acc.: 75.00%] [G loss: 3.342306]\n",
            "100 [D loss: 1.049036, acc.: 0.00%] [G loss: 0.774753]\n",
            "150 [D loss: 0.732542, acc.: 50.00%] [G loss: 3.322635]\n",
            "200 [D loss: 0.497535, acc.: 75.00%] [G loss: 1.903042]\n",
            "250 [D loss: 3.717418, acc.: 0.00%] [G loss: 0.515563]\n",
            "300 [D loss: 1.040916, acc.: 50.00%] [G loss: 2.176764]\n",
            "350 [D loss: 0.044292, acc.: 100.00%] [G loss: 1.559094]\n",
            "400 [D loss: 0.726980, acc.: 50.00%] [G loss: 2.682159]\n",
            "450 [D loss: 0.265348, acc.: 75.00%] [G loss: 3.675426]\n",
            "500 [D loss: 1.927059, acc.: 25.00%] [G loss: 4.617197]\n",
            "550 [D loss: 1.590790, acc.: 50.00%] [G loss: 0.910067]\n",
            "600 [D loss: 0.664665, acc.: 75.00%] [G loss: 1.855151]\n",
            "650 [D loss: 0.982043, acc.: 50.00%] [G loss: 0.353055]\n",
            "700 [D loss: 0.405560, acc.: 100.00%] [G loss: 4.605043]\n",
            "750 [D loss: 0.655857, acc.: 50.00%] [G loss: 2.563517]\n",
            "800 [D loss: 1.401794, acc.: 50.00%] [G loss: 0.692639]\n",
            "850 [D loss: 0.595949, acc.: 75.00%] [G loss: 1.270431]\n",
            "900 [D loss: 2.074251, acc.: 25.00%] [G loss: 1.085764]\n",
            "950 [D loss: 1.830247, acc.: 25.00%] [G loss: 0.424501]\n",
            "1000 [D loss: 0.638178, acc.: 75.00%] [G loss: 0.549478]\n",
            "1050 [D loss: 0.710804, acc.: 75.00%] [G loss: 1.560564]\n",
            "1100 [D loss: 0.494746, acc.: 75.00%] [G loss: 2.238528]\n",
            "1150 [D loss: 0.620451, acc.: 75.00%] [G loss: 0.920538]\n",
            "1200 [D loss: 1.886152, acc.: 25.00%] [G loss: 0.805582]\n",
            "1250 [D loss: 1.979143, acc.: 0.00%] [G loss: 0.839288]\n",
            "1300 [D loss: 0.563378, acc.: 75.00%] [G loss: 1.194275]\n",
            "1350 [D loss: 1.644206, acc.: 25.00%] [G loss: 0.622866]\n",
            "1400 [D loss: 0.635116, acc.: 50.00%] [G loss: 3.000551]\n",
            "1450 [D loss: 1.897515, acc.: 50.00%] [G loss: 0.300414]\n",
            "1500 [D loss: 1.951776, acc.: 25.00%] [G loss: 0.748701]\n",
            "1550 [D loss: 0.316012, acc.: 100.00%] [G loss: 3.710753]\n",
            "1600 [D loss: 0.060502, acc.: 100.00%] [G loss: 2.405326]\n",
            "1650 [D loss: 0.756221, acc.: 75.00%] [G loss: 2.500041]\n",
            "1700 [D loss: 0.651239, acc.: 50.00%] [G loss: 1.164098]\n",
            "1750 [D loss: 1.202930, acc.: 50.00%] [G loss: 0.958087]\n",
            "1800 [D loss: 0.244994, acc.: 100.00%] [G loss: 1.848162]\n",
            "1850 [D loss: 1.168566, acc.: 25.00%] [G loss: 1.232340]\n",
            "1900 [D loss: 1.018616, acc.: 50.00%] [G loss: 1.969756]\n",
            "1950 [D loss: 0.148130, acc.: 100.00%] [G loss: 1.127633]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFgJy_Ogv-Ra",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.makedirs('model_weights', exist_ok=True)\n",
        "generator.save_weights('model_weights/generator_weights.h5')\n",
        "discriminator.save_weights('model_weights/discriminator_weights.h5')\n",
        "combined.save_weights('model_weights/combined_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qv7rorPuhTe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}